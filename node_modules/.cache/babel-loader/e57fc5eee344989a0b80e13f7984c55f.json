{"ast":null,"code":"/**\n * The Lexer class handles tokenizing the input in various ways. Since our\n * parser expects us to be able to backtrack, the lexer allows lexing from any\n * given starting point.\n *\n * Its main exposed function is the `lex` function, which takes a position to\n * lex from and a type of token to lex. It defers to the appropriate `_innerLex`\n * function.\n *\n * The various `_innerLex` functions perform the actual lexing of different\n * kinds.\n */\nvar matchAt = require(\"match-at\");\n\nvar ParseError = require(\"./ParseError\"); // The main lexer class\n\n\nfunction Lexer(input) {\n  this.input = input;\n  this.pos = 0;\n}\n/**\n * The resulting token returned from `lex`.\n *\n * It consists of the token text plus some position information.\n * The position information is essentially a range in an input string,\n * but instead of referencing the bare input string, we refer to the lexer.\n * That way it is possible to attach extra metadata to the input string,\n * like for example a file name or similar.\n *\n * The position information (all three parameters) is optional,\n * so it is OK to construct synthetic tokens if appropriate.\n * Not providing available position information may lead to\n * degraded error reporting, though.\n *\n * @param {string}  text   the text of this token\n * @param {number=} start  the start offset, zero-based inclusive\n * @param {number=} end    the end offset, zero-based exclusive\n * @param {Lexer=}  lexer  the lexer which in turn holds the input string\n */\n\n\nfunction Token(text, start, end, lexer) {\n  this.text = text;\n  this.start = start;\n  this.end = end;\n  this.lexer = lexer;\n}\n/**\n * Given a pair of tokens (this and endToken), compute a “Token” encompassing\n * the whole input range enclosed by these two.\n *\n * @param {Token}  endToken  last token of the range, inclusive\n * @param {string} text      the text of the newly constructed token\n */\n\n\nToken.prototype.range = function (endToken, text) {\n  if (endToken.lexer !== this.lexer) {\n    return new Token(text); // sorry, no position information available\n  }\n\n  return new Token(text, this.start, endToken.end, this.lexer);\n};\n/* The following tokenRegex\n * - matches typical whitespace (but not NBSP etc.) using its first group\n * - does not match any control character \\x00-\\x1f except whitespace\n * - does not match a bare backslash\n * - matches any ASCII character except those just mentioned\n * - does not match the BMP private use area \\uE000-\\uF8FF\n * - does not match bare surrogate code units\n * - matches any BMP character except for those just described\n * - matches any valid Unicode surrogate pair\n * - matches a backslash followed by one or more letters\n * - matches a backslash followed by any BMP character, including newline\n * Just because the Lexer matches something doesn't mean it's valid input:\n * If there is no matching function or symbol definition, the Parser will\n * still reject the input.\n */\n\n\nvar tokenRegex = new RegExp(\"([ \\r\\n\\t]+)|\" + // whitespace\n\"([!-\\\\[\\\\]-\\u2027\\u202A-\\uD7FF\\uF900-\\uFFFF]\" + // single codepoint\n\"|[\\uD800-\\uDBFF][\\uDC00-\\uDFFF]\" + // surrogate pair\n\"|\\\\\\\\(?:[a-zA-Z]+|[^\\uD800-\\uDFFF])\" + // function name\n\")\");\n/**\n * This function lexes a single token.\n */\n\nLexer.prototype.lex = function () {\n  var input = this.input;\n  var pos = this.pos;\n\n  if (pos === input.length) {\n    return new Token(\"EOF\", pos, pos, this);\n  }\n\n  var match = matchAt(tokenRegex, input, pos);\n\n  if (match === null) {\n    throw new ParseError(\"Unexpected character: '\" + input[pos] + \"'\", new Token(input[pos], pos, pos + 1, this));\n  }\n\n  var text = match[2] || \" \";\n  var start = this.pos;\n  this.pos += match[0].length;\n  var end = this.pos;\n  return new Token(text, start, end, this);\n};\n\nmodule.exports = Lexer;","map":{"version":3,"sources":["/Users/justinf/perseus-configured/node_modules/katex/src/Lexer.js"],"names":["matchAt","require","ParseError","Lexer","input","pos","Token","text","start","end","lexer","prototype","range","endToken","tokenRegex","RegExp","lex","length","match","module","exports"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,IAAIA,OAAO,GAAGC,OAAO,CAAC,UAAD,CAArB;;AAEA,IAAIC,UAAU,GAAGD,OAAO,CAAC,cAAD,CAAxB,C,CAEA;;;AACA,SAASE,KAAT,CAAeC,KAAf,EAAsB;AAClB,OAAKA,KAAL,GAAaA,KAAb;AACA,OAAKC,GAAL,GAAW,CAAX;AACH;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASC,KAAT,CAAeC,IAAf,EAAqBC,KAArB,EAA4BC,GAA5B,EAAiCC,KAAjC,EAAwC;AACpC,OAAKH,IAAL,GAAYA,IAAZ;AACA,OAAKC,KAAL,GAAaA,KAAb;AACA,OAAKC,GAAL,GAAWA,GAAX;AACA,OAAKC,KAAL,GAAaA,KAAb;AACH;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;;AACAJ,KAAK,CAACK,SAAN,CAAgBC,KAAhB,GAAwB,UAASC,QAAT,EAAmBN,IAAnB,EAAyB;AAC7C,MAAIM,QAAQ,CAACH,KAAT,KAAmB,KAAKA,KAA5B,EAAmC;AAC/B,WAAO,IAAIJ,KAAJ,CAAUC,IAAV,CAAP,CAD+B,CACP;AAC3B;;AACD,SAAO,IAAID,KAAJ,CAAUC,IAAV,EAAgB,KAAKC,KAArB,EAA4BK,QAAQ,CAACJ,GAArC,EAA0C,KAAKC,KAA/C,CAAP;AACH,CALD;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,IAAII,UAAU,GAAG,IAAIC,MAAJ,CACb,kBAAkD;AAClD,8CADA,GACkD;AAClD,iCAFA,GAEkD;AAClD,qCAHA,GAGkD;AAClD,GALa,CAAjB;AAQA;AACA;AACA;;AACAZ,KAAK,CAACQ,SAAN,CAAgBK,GAAhB,GAAsB,YAAW;AAC7B,MAAIZ,KAAK,GAAG,KAAKA,KAAjB;AACA,MAAIC,GAAG,GAAG,KAAKA,GAAf;;AACA,MAAIA,GAAG,KAAKD,KAAK,CAACa,MAAlB,EAA0B;AACtB,WAAO,IAAIX,KAAJ,CAAU,KAAV,EAAiBD,GAAjB,EAAsBA,GAAtB,EAA2B,IAA3B,CAAP;AACH;;AACD,MAAIa,KAAK,GAAGlB,OAAO,CAACc,UAAD,EAAaV,KAAb,EAAoBC,GAApB,CAAnB;;AACA,MAAIa,KAAK,KAAK,IAAd,EAAoB;AAChB,UAAM,IAAIhB,UAAJ,CACF,4BAA4BE,KAAK,CAACC,GAAD,CAAjC,GAAyC,GADvC,EAEF,IAAIC,KAAJ,CAAUF,KAAK,CAACC,GAAD,CAAf,EAAsBA,GAAtB,EAA2BA,GAAG,GAAG,CAAjC,EAAoC,IAApC,CAFE,CAAN;AAGH;;AACD,MAAIE,IAAI,GAAGW,KAAK,CAAC,CAAD,CAAL,IAAY,GAAvB;AACA,MAAIV,KAAK,GAAG,KAAKH,GAAjB;AACA,OAAKA,GAAL,IAAYa,KAAK,CAAC,CAAD,CAAL,CAASD,MAArB;AACA,MAAIR,GAAG,GAAG,KAAKJ,GAAf;AACA,SAAO,IAAIC,KAAJ,CAAUC,IAAV,EAAgBC,KAAhB,EAAuBC,GAAvB,EAA4B,IAA5B,CAAP;AACH,CAjBD;;AAmBAU,MAAM,CAACC,OAAP,GAAiBjB,KAAjB","sourcesContent":["/**\n * The Lexer class handles tokenizing the input in various ways. Since our\n * parser expects us to be able to backtrack, the lexer allows lexing from any\n * given starting point.\n *\n * Its main exposed function is the `lex` function, which takes a position to\n * lex from and a type of token to lex. It defers to the appropriate `_innerLex`\n * function.\n *\n * The various `_innerLex` functions perform the actual lexing of different\n * kinds.\n */\n\nvar matchAt = require(\"match-at\");\n\nvar ParseError = require(\"./ParseError\");\n\n// The main lexer class\nfunction Lexer(input) {\n    this.input = input;\n    this.pos = 0;\n}\n\n/**\n * The resulting token returned from `lex`.\n *\n * It consists of the token text plus some position information.\n * The position information is essentially a range in an input string,\n * but instead of referencing the bare input string, we refer to the lexer.\n * That way it is possible to attach extra metadata to the input string,\n * like for example a file name or similar.\n *\n * The position information (all three parameters) is optional,\n * so it is OK to construct synthetic tokens if appropriate.\n * Not providing available position information may lead to\n * degraded error reporting, though.\n *\n * @param {string}  text   the text of this token\n * @param {number=} start  the start offset, zero-based inclusive\n * @param {number=} end    the end offset, zero-based exclusive\n * @param {Lexer=}  lexer  the lexer which in turn holds the input string\n */\nfunction Token(text, start, end, lexer) {\n    this.text = text;\n    this.start = start;\n    this.end = end;\n    this.lexer = lexer;\n}\n\n/**\n * Given a pair of tokens (this and endToken), compute a “Token” encompassing\n * the whole input range enclosed by these two.\n *\n * @param {Token}  endToken  last token of the range, inclusive\n * @param {string} text      the text of the newly constructed token\n */\nToken.prototype.range = function(endToken, text) {\n    if (endToken.lexer !== this.lexer) {\n        return new Token(text); // sorry, no position information available\n    }\n    return new Token(text, this.start, endToken.end, this.lexer);\n};\n\n/* The following tokenRegex\n * - matches typical whitespace (but not NBSP etc.) using its first group\n * - does not match any control character \\x00-\\x1f except whitespace\n * - does not match a bare backslash\n * - matches any ASCII character except those just mentioned\n * - does not match the BMP private use area \\uE000-\\uF8FF\n * - does not match bare surrogate code units\n * - matches any BMP character except for those just described\n * - matches any valid Unicode surrogate pair\n * - matches a backslash followed by one or more letters\n * - matches a backslash followed by any BMP character, including newline\n * Just because the Lexer matches something doesn't mean it's valid input:\n * If there is no matching function or symbol definition, the Parser will\n * still reject the input.\n */\nvar tokenRegex = new RegExp(\n    \"([ \\r\\n\\t]+)|\" +                                 // whitespace\n    \"([!-\\\\[\\\\]-\\u2027\\u202A-\\uD7FF\\uF900-\\uFFFF]\" +  // single codepoint\n    \"|[\\uD800-\\uDBFF][\\uDC00-\\uDFFF]\" +               // surrogate pair\n    \"|\\\\\\\\(?:[a-zA-Z]+|[^\\uD800-\\uDFFF])\" +           // function name\n    \")\"\n);\n\n/**\n * This function lexes a single token.\n */\nLexer.prototype.lex = function() {\n    var input = this.input;\n    var pos = this.pos;\n    if (pos === input.length) {\n        return new Token(\"EOF\", pos, pos, this);\n    }\n    var match = matchAt(tokenRegex, input, pos);\n    if (match === null) {\n        throw new ParseError(\n            \"Unexpected character: '\" + input[pos] + \"'\",\n            new Token(input[pos], pos, pos + 1, this));\n    }\n    var text = match[2] || \" \";\n    var start = this.pos;\n    this.pos += match[0].length;\n    var end = this.pos;\n    return new Token(text, start, end, this);\n};\n\nmodule.exports = Lexer;\n"]},"metadata":{},"sourceType":"script"}